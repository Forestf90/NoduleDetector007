{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2TrainUnet_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Forestf90/NoduleDetector007/blob/master/NoduleDetector007.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKs1fhvAR5O1"
      },
      "source": [
        "# NoduleDetector007"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAViUsjiL7QC"
      },
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqCsDcXNL7yT"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path_nb = r'/content/drive/My Drive/'\n",
        "sys.path.append(path_nb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihC1pcKTR5O4"
      },
      "source": [
        "outfolder = '/content/drive/MyDrive/out/LungNoduleDetectionClassification/0001_0120/'\n",
        "datafolder = outfolder+'processeddata'\n",
        "weightsfolder = outfolder+'modelweights'\n",
        "\n",
        "noduleimages=np.load(datafolder+\"/noduleimages_0001_0120.npy\")\n",
        "nodulemasks=np.load(datafolder+\"/nodulemasks_0001_0120.npy\")\n",
        "\n",
        "nodulemasks = nodulemasks.astype(float)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzGo31UlR5O5"
      },
      "source": [
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential,load_model,Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, SpatialDropout2D\n",
        "from tensorflow.keras.layers import Input, Concatenate, UpSampling2D, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "import pandas as pd\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import h5py\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "\n",
        "K.set_image_data_format('channels_first')\n",
        "tf.keras.backend.set_image_data_format('channels_first')\n",
        "tf.keras.backend.image_data_format()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHeKHgVmR5O5"
      },
      "source": [
        "nodulesize=[np.sum(mask) for mask in nodulemasks]\n",
        "plt.hist([nod for nod in nodulesize if nod<300],bins=50)\n",
        "plt.xlabel(\"Area\")\n",
        "plt.ylabel(\"frequency\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMqUjJCwR5O7"
      },
      "source": [
        "if K.image_data_format()=='channels_last':\n",
        "    noduleimages=noduleimages.reshape(noduleimages.shape[0],512,512,1)\n",
        "    nodulemasks=nodulemasks.reshape(nodulemasks.shape[0],512,512,1)\n",
        "else:\n",
        "    noduleimages=noduleimages.reshape(noduleimages.shape[0],1,512,512)\n",
        "    nodulemasks=nodulemasks.reshape(nodulemasks.shape[0],1,512,512)\n",
        "\n",
        "\n",
        "imagestrain, imagestest, maskstrain, maskstest = train_test_split(noduleimages,nodulemasks,test_size=.20)\n",
        "\n",
        "maskstrain.shape\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUkbgG3YLxBv"
      },
      "source": [
        "\n",
        "num_test=imagestest.shape[0]\n",
        "num_train=imagestrain.shape[0]\n",
        "\n",
        "num_test=10\n",
        "num_train=10\n",
        "if K.image_data_format()=='channels_last':\n",
        "    for index in range(num_test):\n",
        "        print(\"Ground Truth test\")\n",
        "        plt.imshow(np.squeeze(maskstest[index]),cmap=\"gray\")\n",
        "        plt.show()\n",
        "        print(\"Image test\")\n",
        "        plt.imshow(np.squeeze(imagestest[index]), cmap=\"gray\")\n",
        "        plt.show()\n",
        "            \n",
        "    for index in range(num_test):\n",
        "        print(\"Ground Truth train\")\n",
        "        plt.imshow(np.squeeze(maskstrain[index]),cmap=\"gray\")\n",
        "        plt.show()\n",
        "        print(\"Image train\")\n",
        "        plt.imshow(np.squeeze(imagestrain[index]), cmap=\"gray\")\n",
        "        plt.show()\n",
        "else:\n",
        "    for index in range(num_test):\n",
        "        print(\"Ground Truth test\")\n",
        "        plt.imshow(maskstest[index,0],cmap=\"gray\")\n",
        "        plt.show()\n",
        "        print(\"Image test\")\n",
        "        plt.imshow(imagestest[index,0], cmap=\"gray\")\n",
        "        plt.show()\n",
        "            \n",
        "    for index in range(num_test):\n",
        "        print(\"Ground Truth train\")\n",
        "        plt.imshow(maskstrain[index,0],cmap=\"gray\")\n",
        "        plt.show()\n",
        "        print(\"Image train\")\n",
        "        plt.imshow(imagestrain[index,0], cmap=\"gray\")\n",
        "        plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiTKjZKlR5O7"
      },
      "source": [
        "#Code sourced from https://www.kaggle.com/c/data-science-bowl-2017#tutorial\n",
        "smooth = 1.0\n",
        "width = 32\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUdhZyvPR5O8"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "def get_model(img_size, num_classes):\n",
        "    \n",
        "    if K.image_data_format()=='channels_first':\n",
        "        input_shape = (1,512, 512)\n",
        "        print((1,512, 512))\n",
        "    else:\n",
        "        input_shape = (512, 512,1)\n",
        "        print((512, 512,1))\n",
        "\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    ### [First half of the network: downsampling inputs] ###\n",
        "    # Entry block\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "    for filters in [64, 128, 256]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    ### [Second half of the network: upsampling inputs] ###\n",
        "\n",
        "    for filters in [256, 128, 64, 32]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.UpSampling2D(2)(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
        "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    # Add a per-pixel classification layer\n",
        "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "K.clear_session()\n",
        "\n",
        "# Build model\n",
        "model = get_model((512,512), 1)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2MA4hEiR5O-",
        "scrolled": true
      },
      "source": [
        "import tensorflow as tf\n",
        "filepath=\"/content/drive/My Drive/Colab Notebooks/MS.hdf5\"\n",
        "\n",
        "model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef, 'accuracy'])\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True)\n",
        "history=model.fit(imagestrain, maskstrain, batch_size=4, epochs=10, verbose=1, shuffle=True,\n",
        "              callbacks=[checkpoint],validation_data=(imagestest,maskstest))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeKCFb-aR5O_"
      },
      "source": [
        "history\n",
        "print(history.history.keys())\n",
        "plt.plot(history.history['dice_coef'], color='b')\n",
        "plt.plot(history.history['val_dice_coef'], color='g')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Dice Coefficient\")\n",
        "plt.legend([\"Train\", \"Validation\"])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(history.history['accuracy'], color='b')\n",
        "plt.plot(history.history['val_accuracy'], color='g')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"Train\", \"Validation\"])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], color='b')\n",
        "plt.plot(history.history['val_loss'], color='g')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend([\"Train\", \"Validation\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6vCFd3WR5O_"
      },
      "source": [
        "model.evaluate(imagestest,maskstest, batch_size=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYNwzsemLxB4"
      },
      "source": [
        "imagestest.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr41tvKpR5PA"
      },
      "source": [
        "\n",
        "if K.image_data_format()=='channels_last':\n",
        "\n",
        "    num_test=imagestest.shape[0]\n",
        "    imgs_mask_test = np.ndarray([num_test,512,512,1],dtype=np.float32)\n",
        "\n",
        "    for i in range(num_test):\n",
        "        imgs_mask_test[i] = model.predict([imagestest[i:i+1]], verbose=0)[0]\n",
        "\n",
        "    print(imgs_mask_test.shape)\n",
        "\n",
        "    sumoverlap=[]\n",
        "    for i in range(num_test):\n",
        "        sumoverlap.append(np.sum(maskstest[i]*imgs_mask_test[i]))\n",
        "\n",
        "    print(len([ov for ov in sumoverlap if ov>1])/len(sumoverlap))\n",
        "\n",
        "else:\n",
        "    num_test=imagestest.shape[0]\n",
        "    imgs_mask_test = np.ndarray([num_test,1,512,512],dtype=np.float32)\n",
        "\n",
        "    for i in range(num_test):\n",
        "        imgs_mask_test[i] = model.predict([imagestest[i:i+1]], verbose=0)[0]\n",
        "\n",
        "\n",
        "    sumoverlap=[]\n",
        "    for i in range(num_test):\n",
        "        sumoverlap.append(np.sum(maskstest[i,0]*imgs_mask_test[i,0]))\n",
        "\n",
        "    print(len([ov for ov in sumoverlap if ov>1])/len(sumoverlap))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT0UUllpR5PA"
      },
      "source": [
        "index=1\n",
        "\n",
        "if K.image_data_format()=='channels_last':\n",
        "    print(\"Predicted\")\n",
        "    plt.imshow(np.squeeze(imgs_mask_test[index]), cmap=\"gray\")\n",
        "    plt.show()\n",
        "    print(\"Ground Truth\")\n",
        "    plt.imshow(np.squeeze(maskstest[index]),cmap=\"gray\")\n",
        "    plt.show()\n",
        "    print(\"Image\")\n",
        "    plt.imshow(np.squeeze(imagestest[index]), cmap=\"gray\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Predicted\")\n",
        "    plt.imshow(imgs_mask_test[index,0], cmap=\"gray\")\n",
        "    plt.show()\n",
        "    print(\"Ground Truth\")\n",
        "    plt.imshow(maskstest[index,0],cmap=\"gray\")\n",
        "    plt.show()\n",
        "    print(\"Image\")\n",
        "    plt.imshow(imagestest[index,0], cmap=\"gray\")\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}